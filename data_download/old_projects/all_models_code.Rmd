---
title: "All models download code"
author: "Janelle Christensen"
date: "8/24/2020"
output: 'HTML'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Future Data, single models

## Daily Future single models

This code will download all models, all RCPs and place them in csv's that have RCP 4.5 and RCP 8.5 for each model in a single csv (i.e. inmcm4 will be its own csv with the RCP 4.5 and RCP 8.5 futures in it)

```{r}

start = 2020 

end = 2099 

#"CCSM4", - problems with 2025

climmodel <- c("inmcm4","NorESM1-M", "MRI-CGCM3", "MIROC5", "IPSL-CM5A-LR", "HadGEM2-CC365", "GFDL-ESM2G", "CanESM2", "CCSM4","CSIRO-Mk3-6-0","CNRM-CM5","BNU-ESM" )# climate model names
for(m in climmodel){ #start loop for the different climate models
  #initialize some variables to hold data 
  
  holder <- NULL 
  
  mydat <- NULL 
  
  mydat2 <- NULL 
  
  mydat3 <- NULL 
  
  #This is the loop that runs across all the climate variables you want to download for RCP 8.5 
  
  #"agdd", fix this not a part of the website 8-20-20
  
  
  for(climvar in c("soil_water", "runoff", "rain","accumswe", "PET", "Deficit", "AET")){ #start loop for 8.5
    
    
    
    print(paste("downloading",climvar, "daily 8.5", m))#this is a progress update as the loop runs 
    
    
    for(yr in c(start:end)){# for each climate variable loop across the year.  allows users to select range if not interested in all data 
      
      
      #Specify URL where are stored on cloud 
      # leap years have end date set at yr + 1 01-01
      # set if else for future data
      
      leap <- lubridate::leap_year(yr) 
      if(leap == TRUE){
        enddate <- paste(yr,"12-31", sep = "-")
      } else {
        enddate <- paste(yr + 1, "01-01", sep = "-")
      }
      
      data_url<-paste("http://www.yellowstone.solutions/thredds/ncss/daily_or_monthly/gcm/rcp85/",m,"/V_1_5_",yr,"_",m,"_rcp85_",climvar,".nc4?var=",climvar,"&latitude=",lat,"&longitude=",lon,"&time_start=",yr,"-01-01T12%3A00%3A00Z&time_end=",enddate,"T12%3A00%3A00Z&accept=csv_file",sep ="") 
      
      holder <-data.frame(fread(data_url, 
                                verbose=FALSE, 
                                showProgress = FALSE,
      ))#temporary holder for subsets downloaded from cloud 
      
      mydat<-rbind(mydat, holder)#file that grows by adding each chunk downloaded from cloud 
      
      date <- mydat$time # dates don't download correctly without this
      
    }#end loop across years for rcp 8.5
    
    mydat2<-cbind(mydat2,mydat[,4])#append just the water balance data from each downloaded chunk 
    
    mydat<-NULL#reset this variable so it can accommodate a new column name given the new water balance variable it's extracting at each loop cycle 
    
  }#end loop across climate variables for 8.5
  
  
  
  mydat3<-cbind(date,holder[,2:3],mydat2)#join the data with metadata including date, lat, long 
  
  head(mydat3) 
  
  
  # ----------
  # Create loop for downloading the data rcp 4.5
  # ----------

  #initialize some variables to hold data

  holder <- NULL

  mydat <- NULL

  mydat2 <- NULL

  mydat4 <- NULL



  #This is the loop that runs across all the climate variables you want to download

  #"agdd", fix this - return when agdd is back on the website

  for(climvar in c("soil_water", "runoff", "rain", "accumswe", "PET", "Deficit", "AET")){ #start loop for RCP 4.5



    print(paste("downloading",climvar, "daily 4.5", m))#this is a progress update as the loop runs


    for(yr in c(start:end)){# for each climate variable loop across the year.  allows users to select range if not interested in all data


      #Specify URL where are stored on cloud
      #leap years are written differently in the future data
      #ifelse for future data

      leap <- lubridate::leap_year(yr)
      if(leap == TRUE){
        enddate <- paste(yr,"12-31", sep = "-")
      } else {
        enddate <- paste(yr + 1, "01-01", sep = "-")
      }

      data_url<-paste("http://www.yellowstone.solutions/thredds/ncss/daily_or_monthly/gcm/rcp45/",m,"/V_1_5_",yr,"_",m,"_rcp45_",climvar,".nc4?var=",climvar,"&latitude=",lat,"&longitude=",lon,"&time_start=",yr,"-01-01T12%3A00%3A00Z&time_end=",enddate,"T12%3A00%3A00Z&accept=csv_file",sep ="")

      holder <-data.frame(fread(data_url,
                                verbose=FALSE,
                                showProgress = FALSE,
      )) #temporary holder for subsets downloaded from cloud

      mydat<-rbind(mydat, holder) #file that grows by adding each chunk downloaded from cloud


      date <- mydat$time

    }#end loop across years for 4.5

    mydat2<-cbind(mydat2,mydat[,4])#append just the water balance data from each downloaded chunk

    mydat<-NULL#reset this variable so it can accommodate a new column name given the new water balance variable it's extracting at each loop cycle

  }#end loop across climate variables for 4.5

  mydat4<-cbind(mydat3,mydat2) #join the data with metadata including date, lat, long

  # "agdd_daily_85", "agdd_daily_45", - fix this, return when agdd is back on the website
  # make sure the order matches where it was placed in the download order (i.e. if it downloads after rain, it should be placed here in the colnames after rain)

  colnames(mydat4)[]<-c("date", "lat","lon","soil_water_daily_85", "runoff_daily_85", "rain_daily_85",  "accumswe_daily_85", "pet_daily_85", "deficit_daily_85", "aet_daily_85", "soil_water_daily_45", "runoff_daily_45", "rain_daily_45",  "accumswe_daily_45", "pet_daily_45", "deficit_daily_45", "aet_daily_45")
  
  
  # "agdd_daily_85", fix this - not a part of the website 8-20-20
  # make sure the order matches where it was placed in the download order (i.e. if it downloads after rain, it should be placed here in the colnames after rain)

  
# columns are multiplied by 10, need to fix this before writing csv
  
  divide.by.10 <- function(x, na.rm = FALSE) {
    x/10
  }
  
  mydat4 <- mydat3 %>% # fix this change back to mydat5 <- mydat 4
    mutate(lat = as.character(lat),
           lon = as.character(lon)) %>% 
    mutate_if(is.numeric, divide.by.10)
  
  write_csv(mydat4, here::here("raw_data",
                               "future_daily", # fix this change back to mydat5
                               site, 
                               paste("lat",lat,"lon",lon, sep = "_"),
                               paste(site,m,"daily_future.csv", sep = "_"))) #default is a space, sep = "" removes space
  
}# end loop across different climate projections

beep(1)

# here::here allows you to choose a folder in your working directory to save to
# here::here("folder I want to save to (this has to be made in your working directory before you save it)", "subfolder", "subfolder ( subfolders can be as numerous you want them to be, always separated by a comma)", "last thing in the list is the name of the object I'm saving")

```

## Monthly Future single models

This code will download all models, all RCPs and place them in csv's that have RCP 4.5 and RCP 8.5 for each model in a single csv (i.e. inmcm4 will be its own csv with the RCP 4.5 and RCP 8.5 futures in it)

```{r}

# download all models, all rcps

start = 2020 

end = 2099 

#"inmcm4","NorESM1-M","MRI-CGCM3","MIROC5","IPSL-CM5A-LR","HadGEM2-CC365","GFDL-ESM2G","CanESM2","CSIRO-Mk3-6-0","CNRM-CM5","CCSM4","BNU-ESM"


climmodel <- c("inmcm4","NorESM1-M","MRI-CGCM3","MIROC5","IPSL-CM5A-LR","HadGEM2-CC365","GFDL-ESM2G","CanESM2","CSIRO-Mk3-6-0","CNRM-CM5","CCSM4","BNU-ESM")# climate model names
for(m in climmodel){
#initialize some variables to hold data 

holder <- NULL 

mydat <- NULL 

mydat2 <- NULL 

mydat3 <- NULL 



#This is the loop that runs across all the climate variables you want to download 

 # "agdd_monthly", fix this - return once agdd is back on the website
# make sure the order matches where it was placed in the download order (i.e. if it downloads after rain, it should be placed here in the colnames after rain)
  for(climvar in c("soil_water_monthly", "runoff_monthly", "rain_monthly","accumswe_monthly", "PET_monthly", "Deficit_monthly", "AET_monthly")){ 
  
  
  
  print(paste("downloading",climvar, "RCP 8.5", m))#this is a progress update as the loop runs 
  
  #the url uses two variable names for same variable in monthly download string like "PET_monthly" for long name and "pet" for short name 
  
  #the short name is sometimes a different case than the long variable name, so make it lowercase so that 
  
  #url string will work with the format of data stored on the cloud 
  
  varshort<-unlist(strsplit(climvar,"_m"));varshort 
  
  vshort<-varshort[[1]];vshort 
  
  if(vshort=="PET"){ 
    
    vshort<-"pet" 
    
  };vshort 
  
  
  if(vshort=="Deficit"){#change case of short name from upper to lower case 
    
    vshort<-"deficit" 
    
  };vshort 
  
  
  if(vshort=="AET"){ 
    
    vshort<-"aet" 
    
  };vshort 
  
  
  
  for(yr in c(start:end)){# for each climate variable loop across the year.  allows users to select range if not interested in all data 
    
    
    #Specify URL where are stored on cloud 
    
    #data_url<-"http://www.yellowstone.solutions/thredds/ncss/daily_or_monthly/v2_historical/daily/v2_2019_soil_water.nc4?var=soil_water&latitude=45&longitude=-111&time_start=2019-01-01T12%3A00%3A00Z&time_end=2019-12-31T12%3A00%3A00Z&accept=csv_file" 
    
    #access daily data 
    
    #example single variable single year timeseries 
    
    #data_url<-paste("http://www.yellowstone.solutions/thredds/ncss/daily_or_monthly/v2_historical/daily/v2_",yr,"_",climvar,".nc4?var=",climvar,"&latitude=",lat,"&longitude=",lon,"&time_start=",yr,"-01-01T12%3A00%3A00Z&time_end=",yr,"-12-31T12%3A00%3A00Z&accept=csv_file", sep="") 
    
    #single variable single year monthly time series with variable and year specified by user 
    
leap <- lubridate::leap_year(yr) 
    if(leap == TRUE){
      day <- 16
    } else {
      day <- 17
    }
    
    data_url<-paste("http://www.yellowstone.solutions/thredds/ncss/daily_or_monthly/gcm/rcp85/",m,"/V_1_5_",yr,"_",m,"_rcp85_",climvar,".nc4?var=",vshort,"&latitude=",lat,"&longitude=",lon,"&time_start=",yr,"-01-16T05%3A14%3A31.916Z&time_end=",yr,"-12-",day,"T00%3A34%3A14.059Z&accept=csv_file",sep ="") 
    
    
    
    holder <-data.frame(fread(data_url, 
                              verbose=FALSE, 
                              showProgress = FALSE,
    ))#temporary holder for subsets downloaded from cloud 
    
    mydat<-rbind(mydat, holder)#file that grows by adding each chunk downloaded from cloud 
    
    date <- mydat$time
    
    }#end loop across years for rcp 8.5
  
  mydat2<-cbind(mydat2,mydat[,4])#append just the water balance data from each downloaded chunk 
  
  mydat<-NULL#reset this variable so it can accodomate a new column name given the new water balance variable it's extracting at each loop cycle 
  
}#end loop across climate variables for rcp 8.5


mydat3<-cbind(date,holder[,2:3],mydat2)#join the data with metadat including date, lat, long 

head(mydat3) 


# ----------
# Create loop for downloading the data rcp 4.5
# ----------

#initialize some variables to hold data 

holder <- NULL 

mydat <- NULL 

mydat2 <- NULL 

mydat4 <- NULL 


#This is the loop that runs across all the climate variables you want to download 
# "agdd_monthly", fix this - removed because it was removed from website
# make sure the order matches where it was placed in the download order (i.e. if it downloads after rain, it should be placed here in the colnames after rain)
for(climvar in c("soil_water_monthly", "runoff_monthly", "rain_monthly", "accumswe_monthly", "PET_monthly", "Deficit_monthly", "AET_monthly")){ 
  
  print(paste("downloading",climvar, "4.5", m))#this is a progress update as the loop runs 
  
  #the url uses two variable names for same variable in monthly download string like "PET_monthly" for long name and "pet" for short name 
  
  #the short name is sometimes a different case than the long variable name, so make it lowercase so that 
  
  #url string will work with the format of data stored on the cloud 
  
  varshort<-unlist(strsplit(climvar,"_m"));varshort 
  
  vshort<-varshort[[1]];vshort 
  
  if(vshort=="PET"){ 
    
    vshort<-"pet" 
    
  };vshort 
  
  
  if(vshort=="Deficit"){#change case of short name from upper to lower case 
    
    vshort<-"deficit" 
    
  };vshort 
  
  
  if(vshort=="AET"){ 
    
    vshort<-"aet" 
    
  };vshort 
  
  
  
  for(yr in c(start:end)){# for each climate variable loop across the year.  allows users to select range if not interested in all data 
    
    
    #Specify URL where are stored on cloud 
    
    leap <- lubridate::leap_year(yr) 
    #leap years have different end days
    if(leap == TRUE){
      day <- 16
    } else {
      day <- 17
    }
    
    data_url<-paste("http://www.yellowstone.solutions/thredds/ncss/daily_or_monthly/gcm/rcp45/",m,"/V_1_5_",yr,"_",m,"_rcp45_",climvar,".nc4?var=",vshort,"&latitude=",lat,"&longitude=",lon,"&time_start=",yr,"-01-16T05%3A14%3A31.916Z&time_end=",yr,"-12-",day,"T00%3A34%3A14.059Z&accept=csv_file",sep ="") 
    
    
    
    holder <-data.frame(fread(data_url, 
                              verbose=FALSE, 
                              showProgress = FALSE,
    ))#temporary holder for subsets downloaded from cloud 
    
    mydat<-rbind(mydat, holder)#file that grows by adding each chunk downloaded from cloud 
    
    date <- mydat$time
    
  }#end loop across years 
  
  mydat2<-cbind(mydat2,mydat[,4])#append just the water balance data from each downloaded chunk 
  
  mydat<-NULL#reset this variable so it can accommodate a new column name given the new water balance variable it's extracting at each loop cycle 
  
}#end loop across climate variables 

mydat4<-cbind(mydat3,mydat2) #join the data with metadata including date, lat, lon
# "agdd_monthly_85", fix this - was removed because agdd was removed from website
## make sure the order matches where it was placed in the download order (i.e. if it downloads after rain, it should be placed here in the colnames after rain)
colnames(mydat4)[]<-c("date", "lat","lon","soil_water_monthly_85", "runoff_monthly_85", "rain_monthly_85",  "accumswe_monthly_85", "pet_monthly_85", "deficit_monthly_85", "aet_monthly_85", "soil_water_monthly_45", "runoff_monthly_45", "rain_monthly_45",  "accumswe_monthly_45", "pet_monthly_45", "deficit_monthly_45", "aet_monthly_45") 

divide.by.10 <- function(x, na.rm = FALSE) {
  x/10
}

mydat5 <- mydat4 %>% 
  mutate(lat = as.character(lat),
         lon = as.character(lon)) %>% 
  mutate_if(is.numeric, divide.by.10)


write_csv(mydat5, here::here("raw_data",
                             "future_monthly",
                             site,
                             paste("lat",lat,"lon",lon, sep = "_"),
                             paste(site,"lat", lat, "lon", lon, m,"monthly_future.csv", sep = "_"))) #default is a space, sep = "" removes space

}# end loop across different climate projections

beep(1)

# here::here allows you to choose a folder in your working directory to save to
# here::here("folder I want to save to (this has to be made in your working directory before you save it)", "subfolder", "subfolder ( subfolders can be as numerous you want them to be, always separated by a commma)", "last thing in the list is the name of the object I'm saving")

```
